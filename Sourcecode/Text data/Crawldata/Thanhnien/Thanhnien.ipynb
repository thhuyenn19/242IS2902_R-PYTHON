{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D678L7tivPev",
        "outputId": "57614840-5008-4be8-9d17-01660e152972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Header giả lập trình duyệt để tránh bị chặn\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "# Danh sách để lưu dữ liệu từ nhiều trang\n",
        "all_data = []\n",
        "\n",
        "# Lặp qua các trang từ 2 đến 68\n",
        "for page in range(2, 68):\n",
        "    url = f\"https://thanhnien.vn/timelinelist/18550/{page}.htm\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            articles = soup.find_all(\"div\", class_=\"box-category-item\")\n",
        "\n",
        "            for article in articles:\n",
        "                title_tag = article.find(\"h3\", class_=\"box-title-text\")\n",
        "                title = title_tag.get_text(strip=True) if title_tag else \"Không có tiêu đề\"\n",
        "\n",
        "                link_tag = title_tag.find(\"a\") if title_tag else None\n",
        "                link = f\"https://thanhnien.vn{link_tag['href']}\" if link_tag else \"Không có link\"\n",
        "\n",
        "                all_data.append({\"Title\": title, \"Link\": link})\n",
        "\n",
        "        time.sleep(1)  # Tránh bị chặn do gửi quá nhiều request liên tục\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi lấy dữ liệu từ {url}: {e}\")\n",
        "\n",
        "# Danh sách để lưu dữ liệu chi tiết từ từng bài viết\n",
        "detailed_data = []\n",
        "\n",
        "# Truy cập từng bài viết để lấy thời gian đăng bài\n",
        "for article in all_data:\n",
        "    article_url = article[\"Link\"]\n",
        "\n",
        "    try:\n",
        "        article_response = requests.get(article_url, headers=headers)\n",
        "\n",
        "        if article_response.status_code == 200:\n",
        "            article_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
        "            time_tag = article_soup.find(\"div\", {\"data-role\": \"publishdate\"})\n",
        "            publish_time = time_tag.get_text(strip=True) if time_tag else \"Không có thời gian\"\n",
        "\n",
        "            # Chuyển đổi định dạng ngày tháng từ dd/mm/yyyy -> dd-mm-yyyy\n",
        "            try:\n",
        "                formatted_date = datetime.strptime(publish_time.split()[0], \"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
        "            except:\n",
        "                formatted_date = \"Không có thời gian\"\n",
        "\n",
        "            detailed_data.append({\n",
        "                \"Title\": article[\"Title\"],\n",
        "                \"Link\": article[\"Link\"],\n",
        "                \"Publish Time\": formatted_date\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi lấy dữ liệu từ {article_url}: {e}\")\n",
        "\n",
        "# Chuyển dữ liệu thành DataFrame\n",
        "df_detailed = pd.DataFrame(detailed_data)\n",
        "\n",
        "# Xuất dữ liệu ra file CSV\n",
        "df_detailed.to_csv(\"thanhnien_news_pages_2_to_68.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Dữ liệu đã được lưu vào thanhnien_news_pages_2_to_68.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQcB-vXd1OJ7",
        "outputId": "735bd6e2-5997-4217-9895-9856a10cf210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu đã được lưu vào thanhnien_news_pages_2_to_6.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Đọc dữ liệu từ file CSV\n",
        "file_path = \"thanhnien_news_pages_2_to_6.csv\"\n",
        "df = pd.read_csv(file_path, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Chuyển cột \"Publish Time\" về kiểu datetime, bỏ giá trị không hợp lệ\n",
        "df[\"Publish Time\"] = pd.to_datetime(df[\"Publish Time\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
        "\n",
        "# Lọc dữ liệu từ 29-09-2019 đến 30-09-2024\n",
        "start_date = \"29-09-2019\"\n",
        "end_date = \"31-12-2024\"\n",
        "df_filtered = df[(df[\"Publish Time\"] >= start_date) & (df[\"Publish Time\"] <= end_date)]\n",
        "\n",
        "# Xuất dữ liệu đã lọc ra file CSV mới\n",
        "filtered_file_path = \"thanhnien_news_filtered_1.csv\"\n",
        "df_filtered.to_csv(filtered_file_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"Dữ liệu đã được lưu vào {filtered_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO2x7tc91n6a",
        "outputId": "928a66e8-5b11-49d3-de0c-b50a0a1a8cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu đã được lưu vào thanhnien_news_filtered_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Đọc dữ liệu từ file CSV đã tải lên\n",
        "# Changed filename to the correct one created in previous step\n",
        "df = pd.read_csv(\"/content/thanhnien_news_filtered_1.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "# Chuyển cột \"Publish Time\" về kiểu datetime, với định dạng ngày tháng dd-mm-yyyy\n",
        "df[\"Publish Time\"] = pd.to_datetime(df[\"Publish Time\"]).dt.strftime(\"%d-%m-%Y\")\n",
        "\n",
        "# Lưu dữ liệu đã chuyển đổi ra file CSV mới\n",
        "df.to_csv(\"thanhnien_news_filtered_1_final.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Cột Publish Time đã được chuyển đổi về định dạng dd-mm-yyyy và lưu vào file thanhnien_news_filtered_1_final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqi7slc76-Jz",
        "outputId": "7ae790ad-2671-4ad5-fa87-7e6e84f3ca8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cột Publish Time đã được chuyển đổi về định dạng dd-mm-yyyy và lưu vào file thanhnien_news_filtered_1_final.csv\n"
          ]
        }
      ]
    }
  ]
}